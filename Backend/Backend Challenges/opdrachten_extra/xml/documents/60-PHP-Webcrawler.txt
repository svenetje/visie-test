Quick Details
Opdracht ID : 60
Opdracht titel : Webcrawler
Opdracht Programmeertalen en/of tech : PHP
Opdracht (geschatte) moeilijkheidsgraad : Gemiddeld
Opdracht Eisen : GUI voor keywords en limitaties instellen
Opdracht Extra Omschrijving : 
Titel: Webcrawler

Doel: Ontwikkel een webcrawler die een website doorzoekt op basis van opgegeven trefwoorden en beperkingen met behulp van een grafische gebruikersinterface (GUI).

Programmeertaal: PHP

Moeilijkheidsgraad: Gemiddeld

Benodigdheden:
1
Webserver met PHP-ondersteuning (bijvoorbeeld Apache met PHP)
2
Teksteditor of IDE voor het schrijven van PHP-code (bijvoorbeeld Visual Studio Code, PHPStorm)

Opdracht:

1
Creëer een GUI (bijvoorbeeld met Bootstrap of andere CSS-framework) met de volgende velden:
  
Tekstvak voor het invoeren van de URL van de website die gecrawld moet worden.
  
Tekstvak voor het invoeren van trefwoorden (gescheiden door komma's), die gezocht moeten worden op de website.
  
Tekstvak voor het invoeren van het maximumaantal pagina's dat gecrawld moet worden.
  
Dropdown-menu voor het selecteren van de crawl-diepte (bijvoorbeeld: 1, 2, 3).
  
Een knop om het crawl-proces te starten.
  
Een knop om het crawl-proces te stoppen.

2
Schrijf PHP-code (eventueel met behulp van cURL of Simple HTML DOM Parser) om de volgende functionaliteiten te implementeren:
  
De opgegeven website crawlen.
  
Zoeken naar de opgegeven trefwoorden op de gecrawlde pagina's.
  
Limieten instellen voor het aantal gecrawlde pagina's.
  
Crawl-diepte beperken op basis van de geselecteerde optie in de dropdown-menu.
  
Een progressiebalk of indicator tonen om de voortgang van het crawl-proces te weergeven.

3
Presenteer de resultaten van de webcrawler in een tabelvorm in de GUI, met de volgende kolommen:
  
URL van de gevonden pagina.
  
Trefwoorden die gevonden zijn op die pagina (gescheiden door komma's).
  
Aantal keren dat elk trefwoord gevonden is op de pagina.
  
Optioneel: Timestamp van het moment waarop de pagina is gecrawld.

4
Zorg ervoor dat de webcrawler zich houdt aan de robots.txt van de gecrawlde website, en voorkom dat de webcrawler in een oneindige loop terechtkomt
Implementeer ook een pauze- en hervatfunctie om de webcrawler te kunnen pauzeren en hervatten tijdens het crawl-proces.

Tips en bronnen:

1
PHP Documentatie: https://www.php.net/manual/nl/
2
Bootstrap voor het bouwen van de GUI: https://getbootstrap.com/
3
cURL in PHP: https://www.php.net/manual/nl/book.curl.php
4
Simple HTML DOM Parser: https://simplehtmldom.sourceforge.io/
5
Instructies voor het lezen van robots.txt: https://developers.google.com/search/docs/advanced/robots/create-robots-txt
6
Pauze- en hervatfunctie in PHP: https://www.php.net/manual/nl/function.sleep.php
